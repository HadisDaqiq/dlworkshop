{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-07 20:08:37--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "Archive:  /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus.zip\n",
      "   creating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/\n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/.DS_Store  \n",
      "   creating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/__MACOSX/\n",
      "   creating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/\n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/chameleons.pdf  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_conversations.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/raw_script_urls.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/README.txt  \n",
      "  inflating: /home/jendrik/data/workshop_data/cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
     ]
    }
   ],
   "source": [
    "! wget -c --retry-connrefused --tries=0 http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip -O ~/data/workshop_data/cornell_movie_dialogs_corpus.zip\n",
    "! unzip ~/data/workshop_data/cornell_movie_dialogs_corpus.zip -d ~/data/workshop_data/cornell_movie_dialogs_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "data_dir = home + '/data/workshop_data/cornell_movie_dialogs_corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(data_dir, corpus_name)\n",
    "\n",
    "def print_lines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "print_lines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file into a dictionary of fields\n",
    "def load_lines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            line_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                line_obj[field] = values[i]\n",
    "            lines[line_obj['lineID']] = line_obj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def load_conversations(file_name, lines, fields):\n",
    "    conversations = []\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            conv_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                conv_obj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(conv_obj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            conv_obj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                conv_obj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(conv_obj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extract_sentence_pairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            input_line = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            target_line = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if input_line and target_line:\n",
    "                qa_pairs.append([input_line, target_line])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\n'\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# Load lines and process conversations\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = load_lines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = load_conversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extract_sentence_pairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "# Print a sample of lines\n",
    "print(\"\\nSample lines from file:\")\n",
    "print_lines(datafile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
